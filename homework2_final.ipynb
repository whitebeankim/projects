{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79174ee5-643d-4873-a327-50465a158b1b",
   "metadata": {},
   "source": [
    "# 1. Binary Classification on Text Data\n",
    "## (a) Download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "472f732e-246f-488b-b802-e67f49f22c63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get the training and testing data\n",
    "df_train = pd.read_csv('./hw2-data/train.csv') # df = data frame\n",
    "df_test  = pd.read_csv('./hw2-data/test.csv')\n",
    "\n",
    "df_train.head() # limit by 5 rows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "823bcc07-24a5-497c-96bd-fdc8a31dcc8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7613 entries, 0 to 7612\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        7613 non-null   int64 \n",
      " 1   keyword   7552 non-null   object\n",
      " 2   location  5080 non-null   object\n",
      " 3   text      7613 non-null   object\n",
      " 4   target    7613 non-null   int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 297.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# Check the number of training data\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "0dfc6476-552d-4822-a269-6c0ad171cb69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3263 entries, 0 to 3262\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        3263 non-null   int64 \n",
      " 1   keyword   3237 non-null   object\n",
      " 2   location  2158 non-null   object\n",
      " 3   text      3263 non-null   object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 102.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# Check the number of test data\n",
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "2b7ffc69-cc3f-4ea3-8ed7-c938e96dfa4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.57034\n",
      "1    0.42966\n",
      "Name: target, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Check the percentage of the training tweets that are real disasters\n",
    "x = df_train.target\n",
    "print(x.value_counts(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfeb0c12-7e9d-4f9b-b62b-63ea7acaf5ab",
   "metadata": {},
   "source": [
    "## (b) Split the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "c77bf228-2b05-4158-85ad-e18eaabc8ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, develop = train_test_split(df_train, train_size=0.7, test_size=0.3, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e6b91890-3816-457a-8c22-72252738be91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5329 entries, 2345 to 5640\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        5329 non-null   int64 \n",
      " 1   keyword   5290 non-null   object\n",
      " 2   location  3583 non-null   object\n",
      " 3   text      5329 non-null   object\n",
      " 4   target    5329 non-null   int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 249.8+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "4688184b-fea5-43e4-9823-ad1f77462ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2284 entries, 3999 to 3347\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        2284 non-null   int64 \n",
      " 1   keyword   2262 non-null   object\n",
      " 2   location  1497 non-null   object\n",
      " 3   text      2284 non-null   object\n",
      " 4   target    2284 non-null   int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 107.1+ KB\n"
     ]
    }
   ],
   "source": [
    "develop.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "cc8d9e6c-dbe0-4335-a39b-c0d930d3fffd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2345</th>\n",
       "      <td>3373</td>\n",
       "      <td>demolition</td>\n",
       "      <td>NaN</td>\n",
       "      <td>General News Û¢åÊ'Demolition of houses on wat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6112</th>\n",
       "      <td>8726</td>\n",
       "      <td>sinking</td>\n",
       "      <td>HOMRA.</td>\n",
       "      <td>In your eyes I see the hope\\nI once knew.\\nI'm...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5764</th>\n",
       "      <td>8226</td>\n",
       "      <td>riot</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>'Without an ally near you can't use this skill...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3591</th>\n",
       "      <td>5130</td>\n",
       "      <td>fatal</td>\n",
       "      <td>Thane</td>\n",
       "      <td>11-Year-Old Boy Charged With Manslaughter of T...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1175</th>\n",
       "      <td>1692</td>\n",
       "      <td>bridge%20collapse</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2 Injured 1 missing in bridge collapse in cent...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id            keyword        location  \\\n",
       "2345  3373         demolition             NaN   \n",
       "6112  8726            sinking          HOMRA.   \n",
       "5764  8226               riot  United Kingdom   \n",
       "3591  5130              fatal           Thane   \n",
       "1175  1692  bridge%20collapse             NaN   \n",
       "\n",
       "                                                   text  target  \n",
       "2345  General News Û¢åÊ'Demolition of houses on wat...       0  \n",
       "6112  In your eyes I see the hope\\nI once knew.\\nI'm...       0  \n",
       "5764  'Without an ally near you can't use this skill...       0  \n",
       "3591  11-Year-Old Boy Charged With Manslaughter of T...       1  \n",
       "1175  2 Injured 1 missing in bridge collapse in cent...       1  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c893e5e-8246-4ae7-aa88-affa917e12eb",
   "metadata": {},
   "source": [
    "## (c) Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "2cf44bd4-93d9-4abe-a03a-47c6577cac2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "# Convert all the words to lowercase\n",
    "train['text'] = train['text'].str.lower()\n",
    "develop['text'] =develop['text'].str.lower()\n",
    "\n",
    "# Strip URLs since URLs are irrelevant to disaster information\n",
    "train['text'] = train['text'].str.replace(r'http\\S+|www.\\S+', ' ', regex=True)\n",
    "develop['text'] = develop['text'].str.replace(r'http\\S+|www.\\S+', ' ', regex=True)\n",
    "\n",
    "# Strip punctuation since punctuations are irrelevant to disaster information\n",
    "train['text'] = train['text'].str.replace(f'[{string.punctuation}]', ' ', regex=True)\n",
    "develop['text'] = develop['text'].str.replace(f'[{string.punctuation}]', ' ', regex=True)\n",
    "\n",
    "# Strip \\n since \\n are irrelevant to disaster information\n",
    "train['text'] = train['text'].str.replace(f'\\n', ' ', regex=True)\n",
    "develop['text'] = develop['text'].str.replace(f'\\n', ' ', regex=True)\n",
    "\n",
    "# Remove Non-English & numbers characters since we can't distinguish the severity of disaster based on numbers and non english words\n",
    "non_english = str.maketrans(\"\", \"\", \"0123456789!@#$%^&*()_+-=[]{}\\\\|;:'\\\",./<>?`~¡¢£¥¦§¨©ª«¬®¯°±²³´µ¶·¸¹º»¼½¾¿ÀÁÂÃÄÅÆÇÈÉÊËÌÍÎÏÐÑÒÓÔÕÖ×ØÙÚÛÜÝÞßàáâãäåæçèéêëìíîïðñòóôõö÷øùúûüýþÿ\")\n",
    "train['text'] = train['text'].str.translate(non_english)\n",
    "develop['text'] = develop['text'].str.translate(non_english)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "d40d822e-97e4-4ab9-b0ae-a14293781455",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2345</th>\n",
       "      <td>3373</td>\n",
       "      <td>demolition</td>\n",
       "      <td>NaN</td>\n",
       "      <td>general news  demolition of houses on waterwa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6112</th>\n",
       "      <td>8726</td>\n",
       "      <td>sinking</td>\n",
       "      <td>HOMRA.</td>\n",
       "      <td>in your eyes i see the hope i once knew  i m s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5764</th>\n",
       "      <td>8226</td>\n",
       "      <td>riot</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>without an ally near you can t use this skill...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3591</th>\n",
       "      <td>5130</td>\n",
       "      <td>fatal</td>\n",
       "      <td>Thane</td>\n",
       "      <td>year old boy charged with manslaughter of tod...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1175</th>\n",
       "      <td>1692</td>\n",
       "      <td>bridge%20collapse</td>\n",
       "      <td>NaN</td>\n",
       "      <td>injured  missing in bridge collapse in centra...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id            keyword        location  \\\n",
       "2345  3373         demolition             NaN   \n",
       "6112  8726            sinking          HOMRA.   \n",
       "5764  8226               riot  United Kingdom   \n",
       "3591  5130              fatal           Thane   \n",
       "1175  1692  bridge%20collapse             NaN   \n",
       "\n",
       "                                                   text  target  \n",
       "2345  general news  demolition of houses on waterwa...       0  \n",
       "6112  in your eyes i see the hope i once knew  i m s...       0  \n",
       "5764   without an ally near you can t use this skill...       0  \n",
       "3591   year old boy charged with manslaughter of tod...       1  \n",
       "1175   injured  missing in bridge collapse in centra...       1  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "806f682d-1176-4465-ae63-09e9093b3243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement Lemmatization\n",
    "from nltk.stem import WordNetLemmatizer\n",
    " \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# For training dset\n",
    "num_train = train.shape[0]\n",
    "for i in range(0, num_train):\n",
    "    # Find the text at each row\n",
    "    sentence = train.iloc[i, 3]\n",
    "\n",
    "    # Split the sentence and make the word list\n",
    "    tokens = sentence.split()\n",
    "    for j in range(0, len(tokens)):\n",
    "        tokens[j] = lemmatizer.lemmatize(tokens[j], pos='v')\n",
    "\n",
    "    # Make the sentence again and put it in the train data\n",
    "    train.iloc[i, 3] = ' '.join(tokens)\n",
    "\n",
    "# For development set\n",
    "num_develop = develop.shape[0]\n",
    "for i in range(0, num_develop):\n",
    "    # Find the text at each row\n",
    "    sentence = develop.iloc[i, 3]\n",
    "\n",
    "    # Split the sentence and make the word list\n",
    "    tokens = sentence.split()\n",
    "    for j in range(0, len(tokens)):\n",
    "        tokens[j] = lemmatizer.lemmatize(tokens[j], pos='v')\n",
    "\n",
    "    # Make the sentence again and put it in the train data\n",
    "    develop.iloc[i, 3] = ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "4eaf581f-d59a-452e-abe4-701b9fb03311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2345</th>\n",
       "      <td>3373</td>\n",
       "      <td>demolition</td>\n",
       "      <td>NaN</td>\n",
       "      <td>general news  demolition of house on waterway...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6112</th>\n",
       "      <td>8726</td>\n",
       "      <td>sinking</td>\n",
       "      <td>HOMRA.</td>\n",
       "      <td>in your eye i see the hope i once know i m sin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5764</th>\n",
       "      <td>8226</td>\n",
       "      <td>riot</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>without an ally near you can t use this skill ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3591</th>\n",
       "      <td>5130</td>\n",
       "      <td>fatal</td>\n",
       "      <td>Thane</td>\n",
       "      <td>year old boy charge with manslaughter of toddl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1175</th>\n",
       "      <td>1692</td>\n",
       "      <td>bridge%20collapse</td>\n",
       "      <td>NaN</td>\n",
       "      <td>injure miss in bridge collapse in central mexi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id            keyword        location  \\\n",
       "2345  3373         demolition             NaN   \n",
       "6112  8726            sinking          HOMRA.   \n",
       "5764  8226               riot  United Kingdom   \n",
       "3591  5130              fatal           Thane   \n",
       "1175  1692  bridge%20collapse             NaN   \n",
       "\n",
       "                                                   text  target  \n",
       "2345  general news  demolition of house on waterway...       0  \n",
       "6112  in your eye i see the hope i once know i m sin...       0  \n",
       "5764  without an ally near you can t use this skill ...       0  \n",
       "3591  year old boy charge with manslaughter of toddl...       1  \n",
       "1175  injure miss in bridge collapse in central mexi...       1  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ccfb64-2b6a-4ba2-9a7b-a6bca5b6996c",
   "metadata": {},
   "source": [
    "## (d) Bag of words model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "4134c951-c03a-411a-a0a6-827367f63bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW Size: 1105\n"
     ]
    }
   ],
   "source": [
    "# Make the binary \"bag of words\" model\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Implement the text list\n",
    "train_text = []\n",
    "for text in train['text']:\n",
    "    train_text.append(text)\n",
    "\n",
    "M = 10 # Include in the vocabulary words that appear in at least M different tweets\n",
    "vectorizer = CountVectorizer(binary=True, min_df=M)\n",
    "X = vectorizer.fit_transform(train_text)\n",
    "bow = vectorizer.get_feature_names_out()\n",
    "len_bow = len(bow)\n",
    "\n",
    "print(\"BOW Size:\", len(bow)) # Size of the \"bag of words\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "6a5ab30a-fcf4-42b5-bebe-825ee34cb8b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5329, 1105)\n"
     ]
    }
   ],
   "source": [
    "X_bow_train = X.toarray()\n",
    "\n",
    "# print(bow)\n",
    "print(X_bow_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "5c598991-9d36-4753-8980-f9a7933af921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2284, 1105)\n"
     ]
    }
   ],
   "source": [
    "# Find the array for the development set\n",
    "X_bow_develop = np.zeros((num_develop, len_bow))\n",
    "\n",
    "for i in range(0, num_develop):\n",
    "    sentence = develop.iloc[i, 3]\n",
    "    X_bow_develop[i, :] = [(word in sentence.split()) for word in bow]\n",
    "  \n",
    "print(X_bow_develop.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf3ee2b-c8db-4e45-b943-648febdecadb",
   "metadata": {},
   "source": [
    "## (e) Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e4157f-a3d1-4a4f-a814-7e5b390b66dd",
   "metadata": {},
   "source": [
    "### i-iii. Train a logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "616ff3f2-7733-446e-881e-96593149bd57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joohyunkim/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/joohyunkim/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Implement logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Instantiate the model\n",
    "log_no_reg = LogisticRegression(penalty=None, random_state=16)\n",
    "lr_l1 = LogisticRegression(penalty='l1', solver='saga', max_iter=16)\n",
    "lr_l2 = LogisticRegression(penalty='l2', random_state=16)\n",
    "\n",
    "y_train = train['target']\n",
    "y_develop = develop['target']\n",
    "# print(y_train.shape)\n",
    "\n",
    "# Fit the model with data\n",
    "log_no_reg.fit(X_bow_train, y_train)\n",
    "lr_l1.fit(X_bow_train, y_train)\n",
    "lr_l2.fit(X_bow_train, y_train)\n",
    "\n",
    "# Predict and calculate F1 score for training and development sets\n",
    "f1_train_no_reg = f1_score(y_train, log_no_reg.predict(X_bow_train))\n",
    "f1_dev_no_reg = f1_score(y_develop, log_no_reg.predict(X_bow_develop))\n",
    "\n",
    "f1_train_l1 = f1_score(y_train, lr_l1.predict(X_bow_train))\n",
    "f1_dev_l1 = f1_score(y_develop, lr_l1.predict(X_bow_develop))\n",
    "\n",
    "f1_train_l2 = f1_score(y_train, lr_l2.predict(X_bow_train))\n",
    "f1_dev_l2 = f1_score(y_develop, lr_l2.predict(X_bow_develop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "4e269e5f-0dbb-43f8-b583-2bf9498d1c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8677225072496098\n",
      "0.825271927794492\n",
      "0.8393186003683242\n",
      "0.720682302771855\n",
      "0.7412353923205341\n",
      "0.7409040793825801\n"
     ]
    }
   ],
   "source": [
    "print(f1_train_no_reg)\n",
    "print(f1_train_l1)\n",
    "print(f1_train_l2)\n",
    "\n",
    "print(f1_dev_no_reg)\n",
    "print(f1_dev_l1)\n",
    "print(f1_dev_l2)\n",
    "#The best classifier for the training set is no regulation and for the test(development) set is l2 with the highest f1 score in each sector. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3ba1a0-37e8-48fe-827a-618c42146622",
   "metadata": {},
   "source": [
    "### v. Inspect the weight vector of the classifier with L1 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "08d5c40e-60ac-49c5-a38a-48095c7aea43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word that has the maximum positive coefficient: wildfire\n",
      "Its coefficient: 3.2754598432875275\n",
      "Word that has the maximum negative coefficient: such\n",
      "Its coefficient: -2.1602140271068238\n"
     ]
    }
   ],
   "source": [
    "#print(lr_l1.coef_.shape)\n",
    "\n",
    "argmax = lr_l1.coef_.argmax()\n",
    "argmin = lr_l1.coef_.argmin()\n",
    "\n",
    "print(\"Word that has the maximum positive coefficient:\", bow[argmax])\n",
    "print(\"Its coefficient:\", lr_l1.coef_[0, argmax])\n",
    "print(\"Word that has the maximum negative coefficient:\", bow[argmin])\n",
    "print(\"Its coefficient:\", lr_l1.coef_[0, argmin])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "95fa8016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1065\n",
      "[[ 0.          0.14569677  0.21953019 ... -0.49492731  0.\n",
      "  -0.38761053]]\n"
     ]
    }
   ],
   "source": [
    "print(argmax)\n",
    "print(lr_l1.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa67680-4630-4267-9c02-d7929c4b7360",
   "metadata": {},
   "source": [
    "## (f) Bernoulli Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "a69d50de-d64e-49ae-9f63-e766814274c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00198544 0.00066181 0.00463269 ... 0.0198544  0.00099272 0.0049636 ]\n",
      " [0.0034617  0.00908698 0.00519256 ... 0.00562527 0.00908698 0.00259628]]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the probability P(y=0), P(y=1) at training data\n",
    "n_y0 = sum(y_train == 0)\n",
    "n_y1 = sum(y_train == 1)\n",
    "p_y0 = sum(y_train == 0) / num_train\n",
    "p_y1 = sum(y_train == 1) / num_train\n",
    " \n",
    "# Calcaulte the P(x_j=1 | y=k) with Laplace smoothing\n",
    "prob_ber = np.zeros((2, len(bow)))\n",
    "\n",
    "for j in range(0, len(bow)):\n",
    "    n_j0 = 0\n",
    "    n_j1 = 0\n",
    "\n",
    "    # Calculate the n_jk\n",
    "    for i in range(0, num_train):\n",
    "        if X_bow_train[i, j] == 1:\n",
    "            if y_train.iloc[i] == 1:\n",
    "                n_j1 = n_j1 + 1\n",
    "            else:\n",
    "                n_j0 = n_j0 + 1\n",
    "        \n",
    "    prob_ber[0, j] = (n_j0+1) / (n_y0+2)\n",
    "    prob_ber[1, j] = (n_j1+1) / (n_y1+2)\n",
    "                \n",
    "print(prob_ber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "f57de0f8-7bd7-4b8d-9f34-8e236452f1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the conditional probability at the development set\n",
    "# P(y|x_1, x_2, ..., x_n) ~ P(y) * P(x_1|y) * P(x_2|y) * .... * P(x_n|y)\n",
    "y_develop_ber = np.array([])\n",
    "\n",
    "for i in range(0, num_develop):\n",
    "    p_y0_dev = p_y0\n",
    "    p_y1_dev = p_y1\n",
    "\n",
    "    for j in range(0, len(bow)):\n",
    "        if X_bow_develop[i, j] == 1:\n",
    "            p_y0_dev = p_y0_dev * prob_ber[0, j]\n",
    "            p_y1_dev = p_y1_dev * prob_ber[1, j]\n",
    "        \n",
    "        if X_bow_develop[i, j] == 0:\n",
    "            p_y0_dev = p_y0_dev * (1 - prob_ber[0, j])\n",
    "            p_y1_dev = p_y1_dev * (1 - prob_ber[1, j])\n",
    "\n",
    "    if p_y0_dev > p_y1_dev:\n",
    "        y_develop_ber = np.append(y_develop_ber, [0])\n",
    "    else:\n",
    "        y_develop_ber = np.append(y_develop_ber, [1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "51ebc839-0f75-4fde-b073-e09601fc2c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.743502824858757\n"
     ]
    }
   ],
   "source": [
    "# Calculate the F1-score\n",
    "f1_develop_ber = f1_score(y_develop, y_develop_ber)\n",
    "print(f1_develop_ber)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59dc5e0b-2777-45cf-9ee1-283cd2f900d2",
   "metadata": {},
   "source": [
    "## (h) N-gram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "6d1c04de-1531-4337-a5b8-010b34792822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get 2-grams\n",
    "M = 10 # Include in the vocabulary words that appear in at least M different tweets\n",
    "vectorizer_2 = CountVectorizer(binary=True, min_df=M, ngram_range=(2,2))\n",
    "X = vectorizer_2.fit_transform(train_text)\n",
    "vec_2gram = vectorizer_2.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "a1c99181-f0e2-49e9-9962-70334adca373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "532\n",
      "['abc news' 'about the' 'about to' 'about trap' 'affect by' 'after the'\n",
      " 'after wave' 'air ambulance' 'airplane accident' 'airport get']\n"
     ]
    }
   ],
   "source": [
    "print(len(vec_2gram))\n",
    "print(vec_2gram[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "5ce957ad-6b06-4f9a-b1cf-e9335c560b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Achieve 2-grams again with large min_df\n",
    "M = 5 # Include in the vocabulary words that appear in at least M different tweets\n",
    "vectorizer_2 = CountVectorizer(binary=True, min_df=M, ngram_range=(2,2))\n",
    "X2 = vectorizer_2.fit_transform(train_text)\n",
    "vec_2gram = vectorizer_2.get_feature_names_out()\n",
    "# print(len(vec_2gram))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "c221d39c-a8a4-4c8c-b394-1cdf33f64984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge 2-grams and 1-grams\n",
    "X_only_2gram_train = X2.toarray()\n",
    "X_2gram_train = np.append(X_bow_train, X_only_2gram_train, axis=1)\n",
    "# print(X_2gram_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "1cae13d8-52f4-4087-919d-423ac7589da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the 2-gram array for the development set\n",
    "X_only_2gram_develop = np.zeros((num_develop, len(vec_2gram)))\n",
    "\n",
    "for i in range(0, num_develop):\n",
    "    sentence = develop.iloc[i, 3]\n",
    "    X_only_2gram_develop[i, :] = [(word in sentence) for word in vec_2gram]\n",
    "    \n",
    "X_2gram_develop = np.append(X_bow_develop, X_only_2gram_develop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "9f18ab24-e0f8-4f77-b130-af46e3e03af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Instantiate the model\n",
    "lr_l2_2gram = LogisticRegression(penalty='l2', random_state=16)\n",
    "\n",
    "# Fit the model with data\n",
    "lr_l2_2gram.fit(X_2gram_train, y_train)\n",
    "\n",
    "# Predict and calculate F1 score for training and development sets\n",
    "f1_train_l2_2gram = f1_score(y_train, lr_l2_2gram.predict(X_2gram_train))\n",
    "f1_dev_l2_2gram = f1_score(y_develop, lr_l2_2gram.predict(X_2gram_develop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "0280dfc8-4a29-4e16-9ee8-719615db7edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8843258042436687\n",
      "0.7441601779755284\n"
     ]
    }
   ],
   "source": [
    "print(f1_train_l2_2gram)\n",
    "print(f1_dev_l2_2gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "6d8b4860-d8ed-4fe3-9cac-3dcfc6ffd685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00198544 0.00066181 0.00463269 ... 0.00264725 0.00959629 0.00033091]\n",
      " [0.0034617  0.00908698 0.00519256 ... 0.00086543 0.00259628 0.00865426]]\n"
     ]
    }
   ],
   "source": [
    "# Implement a Bernoulli Naive Bayes classifier\n",
    "# Calculate the probability P(y=0), P(y=1) at training data\n",
    "n_y0 = sum(y_train == 0)\n",
    "n_y1 = sum(y_train == 1)\n",
    "p_y0 = sum(y_train == 0) / num_train\n",
    "p_y1 = sum(y_train == 1) / num_train\n",
    " \n",
    "# Calcaulte the P(x_j=1 | y=k) with Laplace smoothing\n",
    "len_2gram = len(bow) + len(vec_2gram)\n",
    "prob_ber_2gram = np.zeros((2, len_2gram))\n",
    "\n",
    "for j in range(0, len_2gram):\n",
    "    n_j0 = 0\n",
    "    n_j1 = 0\n",
    "\n",
    "    # Calculate the n_jk\n",
    "    for i in range(0, num_train):\n",
    "        if X_2gram_train[i, j] == 1:\n",
    "            if y_train.iloc[i] == 1:\n",
    "                n_j1 = n_j1 + 1\n",
    "            else:\n",
    "                n_j0 = n_j0 + 1\n",
    "        \n",
    "    prob_ber_2gram[0, j] = (n_j0+1) / (n_y0+2)\n",
    "    prob_ber_2gram[1, j] = (n_j1+1) / (n_y1+2)\n",
    "                \n",
    "print(prob_ber_2gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "7b392ab4-f256-46cc-b183-3f050c612000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the conditional probability at the development set\n",
    "# P(y|x_1, x_2, ..., x_n) ~ P(y) * P(x_1|y) * P(x_2|y) * .... * P(x_n|y)\n",
    "y_develop_ber_2gram = np.array([])\n",
    "\n",
    "for i in range(0, num_develop):\n",
    "    p_y0_dev = p_y0\n",
    "    p_y1_dev = p_y1\n",
    "\n",
    "    for j in range(0, len_2gram):\n",
    "        if X_2gram_develop[i, j] == 1:\n",
    "            p_y0_dev = p_y0_dev * prob_ber_2gram[0, j]\n",
    "            p_y1_dev = p_y1_dev * prob_ber_2gram[1, j]\n",
    "        \n",
    "        if X_2gram_develop[i, j] == 0:\n",
    "            p_y0_dev = p_y0_dev * (1 - prob_ber_2gram[0, j])\n",
    "            p_y1_dev = p_y1_dev * (1 - prob_ber_2gram[1, j])\n",
    "\n",
    "    if p_y0_dev > p_y1_dev:\n",
    "        y_develop_ber_2gram = np.append(y_develop_ber_2gram, [0])\n",
    "    else:\n",
    "        y_develop_ber_2gram = np.append(y_develop_ber_2gram, [1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "24799722-fb24-4f59-83d6-f99062b06a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7284848484848484\n"
     ]
    }
   ],
   "source": [
    "# Calculate the F1-score\n",
    "f1_develop_ber = f1_score(y_develop, y_develop_ber_2gram)\n",
    "print(f1_develop_ber)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4a62ab-eb10-401d-87b5-ac0f4e7d09f6",
   "metadata": {},
   "source": [
    "## (i) Determine performance with the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "12b0bf61-eb54-47e7-854b-f94bed9c5553",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert all the words to lowercase\n",
    "df_test['text'] = df_test['text'].str.lower()\n",
    "\n",
    "# Strip URLs\n",
    "df_test['text'] = df_test['text'].str.replace(r'http\\S+|www.\\S+', ' ', regex=True)\n",
    "\n",
    "# Strip punctuation\n",
    "df_test['text'] = df_test['text'].str.replace(f'[{string.punctuation}]', ' ', regex=True)\n",
    "\n",
    "# Strip \\n\n",
    "df_test['text'] = df_test['text'].str.replace(f'\\n', ' ', regex=True)\n",
    "\n",
    "# Remove Non-English characters\n",
    "non_english = str.maketrans(\"\", \"\", \"0123456789!@#$%^&*()_+-=[]{}\\\\|;:'\\\",./<>?`~¡¢£¥¦§¨©ª«¬®¯°±²³´µ¶·¸¹º»¼½¾¿ÀÁÂÃÄÅÆÇÈÉÊËÌÍÎÏÐÑÒÓÔÕÖ×ØÙÚÛÜÝÞßàáâãäåæçèéêëìíîïðñòóôõö÷øùúûüýþÿ\")\n",
    "df_test['text'] = df_test['text'].str.translate(non_english)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "eeda68ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3263, 1105)\n"
     ]
    }
   ],
   "source": [
    "# Find the array for the development set\n",
    "num_test = df_test.shape[0]\n",
    "X_bow_test = np.zeros((num_test, len_bow))\n",
    "\n",
    "for i in range(0, num_test):\n",
    "    sentence = df_test.iloc[i, 3]\n",
    "    X_bow_test[i, :] = [(word in sentence.split()) for word in bow]\n",
    "  \n",
    "print(X_bow_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "b4e69495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 1 1 0]\n",
      "      target     id\n",
      "0          1      0\n",
      "1          1      2\n",
      "2          1      3\n",
      "3          0      9\n",
      "4          1     11\n",
      "...      ...    ...\n",
      "3258       1  10861\n",
      "3259       1  10865\n",
      "3260       1  10868\n",
      "3261       1  10874\n",
      "3262       0  10875\n",
      "\n",
      "[3263 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "y_test = lr_l1.predict(X_bow_test)\n",
    "\n",
    "df_predict['target'] = pd.DataFrame(y_test).rename(columns={0:'target'})\n",
    "df_predict['id'] = df_test['id']\n",
    "\n",
    "print(y_test)\n",
    "print(df_predict)\n",
    "df_predict.to_csv('./hw2-data/test_predict.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be4c418",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
